{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Code from here was adapted from:\n","https://www.marktechpost.com/2021/04/08/logistic-regression-with-keras/\n","\n","https://keras.io/api/optimizers/\n","\n","https://www.tensorflow.org/guide/keras/train_and_evaluate"],"metadata":{"id":"8l0Z0-0_8Q_e"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtVYF5fleO5E"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","import keras"]},{"cell_type":"code","source":["import sklearn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","iris = datasets.load_iris()\n","X = np.array(iris[\"data\"][:, 2:])# petal length, petal width\n","y = np.array((iris[\"target\"] == 0).astype(int)) # 1 if Iris-Virginica, else 0\n","#Seperate out the testing data\n","X_test = np.array([X[0], X[1], X[-1], X[-2]])\n","y_test = np.array([y[0], y[1], y[-1], y[-2]])\n","X = X[2:148]\n","y = y[2:148]"],"metadata":{"id":"m0-px6IKfSzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","number_of_classes = 1\n","number_of_features = 2\n","model = Sequential()\n","#Tell the model we want to use the sigmoid function to map our data, and tell it that we are using two features\n","model.add(Dense(number_of_classes,activation = 'sigmoid',input_dim = number_of_features))\n","#Optimize for a learning rate of 5 which was decided using trial and error\n","opt = keras.optimizers.Adam(learning_rate=5)\n","#Set gradient desent and find the linear regression with a given loss function of binary cross entrapy\n","model.compile(optimizer=opt, loss='binary_crossentropy', metrics = ['accuracy'])\n","#actually perform the gradient desent over 40 epochs on the training data\n","model.fit(X, y, epochs=40)\n","#test the test data\n","print(\"Test loss, test accuracy: \" +str(model.evaluate(X_test,y_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDIoZTokeS39","executionInfo":{"status":"ok","timestamp":1675707198490,"user_tz":300,"elapsed":2238,"user":{"displayName":"Benjamin Katz","userId":"05452657003282238466"}},"outputId":"f81d9175-9cf3-4249-f216-83334615c5c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","5/5 [==============================] - 0s 4ms/step - loss: 5.7313 - accuracy: 0.5616\n","Epoch 2/40\n","5/5 [==============================] - 0s 3ms/step - loss: 4.6866 - accuracy: 0.6712\n","Epoch 3/40\n","5/5 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.9452\n","Epoch 4/40\n","5/5 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.8699\n","Epoch 5/40\n","5/5 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 6/40\n","5/5 [==============================] - 0s 4ms/step - loss: 1.7874e-06 - accuracy: 1.0000\n","Epoch 7/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0220e-05 - accuracy: 1.0000\n","Epoch 8/40\n","5/5 [==============================] - 0s 4ms/step - loss: 7.6534e-05 - accuracy: 1.0000\n","Epoch 9/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.9618e-04 - accuracy: 1.0000\n","Epoch 10/40\n","5/5 [==============================] - 0s 4ms/step - loss: 3.0916e-04 - accuracy: 1.0000\n","Epoch 11/40\n","5/5 [==============================] - 0s 3ms/step - loss: 4.4201e-04 - accuracy: 1.0000\n","Epoch 12/40\n","5/5 [==============================] - 0s 3ms/step - loss: 5.7287e-04 - accuracy: 1.0000\n","Epoch 13/40\n","5/5 [==============================] - 0s 3ms/step - loss: 5.8078e-04 - accuracy: 1.0000\n","Epoch 14/40\n","5/5 [==============================] - 0s 3ms/step - loss: 5.5176e-04 - accuracy: 1.0000\n","Epoch 15/40\n","5/5 [==============================] - 0s 3ms/step - loss: 5.0706e-04 - accuracy: 1.0000\n","Epoch 16/40\n","5/5 [==============================] - 0s 3ms/step - loss: 4.4338e-04 - accuracy: 1.0000\n","Epoch 17/40\n","5/5 [==============================] - 0s 2ms/step - loss: 3.8422e-04 - accuracy: 1.0000\n","Epoch 18/40\n","5/5 [==============================] - 0s 2ms/step - loss: 3.2698e-04 - accuracy: 1.0000\n","Epoch 19/40\n","5/5 [==============================] - 0s 3ms/step - loss: 2.7441e-04 - accuracy: 1.0000\n","Epoch 20/40\n","5/5 [==============================] - 0s 3ms/step - loss: 2.5082e-04 - accuracy: 1.0000\n","Epoch 21/40\n","5/5 [==============================] - 0s 3ms/step - loss: 2.1336e-04 - accuracy: 1.0000\n","Epoch 22/40\n","5/5 [==============================] - 0s 3ms/step - loss: 2.0039e-04 - accuracy: 1.0000\n","Epoch 23/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.7182e-04 - accuracy: 1.0000\n","Epoch 24/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.6329e-04 - accuracy: 1.0000\n","Epoch 25/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.4479e-04 - accuracy: 1.0000\n","Epoch 26/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.3240e-04 - accuracy: 1.0000\n","Epoch 27/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.2757e-04 - accuracy: 1.0000\n","Epoch 28/40\n","5/5 [==============================] - 0s 4ms/step - loss: 1.1543e-04 - accuracy: 1.0000\n","Epoch 29/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0865e-04 - accuracy: 1.0000\n","Epoch 30/40\n","5/5 [==============================] - 0s 3ms/step - loss: 1.0402e-04 - accuracy: 1.0000\n","Epoch 31/40\n","5/5 [==============================] - 0s 3ms/step - loss: 9.7578e-05 - accuracy: 1.0000\n","Epoch 32/40\n","5/5 [==============================] - 0s 3ms/step - loss: 9.0870e-05 - accuracy: 1.0000\n","Epoch 33/40\n","5/5 [==============================] - 0s 5ms/step - loss: 8.7227e-05 - accuracy: 1.0000\n","Epoch 34/40\n","5/5 [==============================] - 0s 4ms/step - loss: 8.4364e-05 - accuracy: 1.0000\n","Epoch 35/40\n","5/5 [==============================] - 0s 3ms/step - loss: 7.8730e-05 - accuracy: 1.0000\n","Epoch 36/40\n","5/5 [==============================] - 0s 3ms/step - loss: 7.6816e-05 - accuracy: 1.0000\n","Epoch 37/40\n","5/5 [==============================] - 0s 3ms/step - loss: 7.2734e-05 - accuracy: 1.0000\n","Epoch 38/40\n","5/5 [==============================] - 0s 3ms/step - loss: 6.9314e-05 - accuracy: 1.0000\n","Epoch 39/40\n","5/5 [==============================] - 0s 3ms/step - loss: 6.6614e-05 - accuracy: 1.0000\n","Epoch 40/40\n","5/5 [==============================] - 0s 3ms/step - loss: 6.4122e-05 - accuracy: 1.0000\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8beb5215e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 115ms/step - loss: 6.2707e-09 - accuracy: 1.0000\n","Test loss, test accuracy: [6.270697738841591e-09, 1.0]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9d5WFyaj5RGA"},"execution_count":null,"outputs":[]}]}