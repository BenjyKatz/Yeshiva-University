{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MK_DrCNnm6-4sm8aMDtsSFCs8BAqK4hE","timestamp":1677530527054}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kzUN9biudtHQ"},"outputs":[],"source":["# Benjamin Katz\n","# Code source: Jaques Grobler\n","# License: BSD 3 clause\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn import datasets, linear_model\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n"]},{"cell_type":"code","source":["\n","# Load the Boston dataset\n","boston_X, boston_y = datasets.load_boston(return_X_y=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tX761Bzkf8eM","executionInfo":{"status":"ok","timestamp":1677531152685,"user_tz":300,"elapsed":224,"user":{"displayName":"Benjamin Katz","userId":"05452657003282238466"}},"outputId":"8b50a111-4050-49ba-e7f9-301f7c0eef0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","source":["\n","# Split the data into training/testing sets\n","#boston_X_train = boston_X[:-20]\n","#boston_X_test = boston_X[-20:]\n","\n","#Seperate out testing data\n","#get a random distribution of indexes of the data\n","#this will allow testing on a random sample as opposed to just the begining of\n","#the data set or the end\n","shuffled_indexes = np.random.permutation(len(boston_X))\n","#seperate out 20 percent for testing\n","test_size = int(len(boston_X)*.2)\n","#get the testing and training indexes\n","test_indexes = shuffled_indexes[:test_size]\n","train_indexes = shuffled_indexes[test_size:]\n","#set the sets to the actual values\n","boston_X_train = np.zeros((len(boston_X)-test_size, 13))\n","boston_y_train = np.zeros(len(boston_X)-test_size)\n","boston_X_test = np.zeros((test_size,13))\n","boston_y_test = np.zeros(test_size)\n","\n","for i in range(len(train_indexes)):\n","  boston_X_train[i] = boston_X[train_indexes[i]]\n","  boston_y_train[i] = boston_y[train_indexes[i]]\n","for i in range(len(test_indexes)):\n","  boston_X_test[i] = boston_X[test_indexes[i]]\n","  boston_y_test[i] = boston_y[test_indexes[i]]"],"metadata":{"id":"hTZcKF84f_7R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Create linear regression object\n"],"metadata":{"id":"mzdcPhasgJ2s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Train the model using the training sets\n","#Lasso applies the l1 regularization to the model l1 regularization this removes features it deems unimportant by shrinikng the weight to 0\n","regr = linear_model.Lasso()\n","regr.fit(boston_X_train, boston_y_train)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_TAtqxBgKqE","executionInfo":{"status":"ok","timestamp":1677531881701,"user_tz":300,"elapsed":138,"user":{"displayName":"Benjamin Katz","userId":"05452657003282238466"}},"outputId":"d3926f6a-d41d-4b8e-a768-ead72a8ef73b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Lasso()"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["\n","# Make predictions using the testing set\n","boston_y_pred = regr.predict(boston_X_test)\n"],"metadata":{"id":"Q1z7h3HAgLa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# The coefficients\n","print(\"Coefficients: \\n\", regr.coef_)\n","# The mean squared error see more in the write up\n","print(\"Mean squared error: %.2f\" % mean_squared_error(boston_y_test, boston_y_pred))\n","# The coefficient of determination: 1 is perfect prediction\n","print(\"Coefficient of determination: %.2f\" % r2_score(boston_y_test, boston_y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AvoBBhwgMSd","executionInfo":{"status":"ok","timestamp":1677531631984,"user_tz":300,"elapsed":5,"user":{"displayName":"Benjamin Katz","userId":"05452657003282238466"}},"outputId":"8d73d1a9-99d8-46ab-d83e-d15505e12a26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Coefficients: \n"," [-0.06725272  0.03678685 -0.00334174  0.         -0.          1.53442812\n","  0.00383074 -0.61077531  0.25639811 -0.01576973 -0.70086266  0.00897009\n"," -0.66332969]\n","Mean squared error: 33.31\n","Coefficient of determination: 0.67\n"]}]}]}